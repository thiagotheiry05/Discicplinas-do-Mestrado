{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I4pgzLVtBTP"
      },
      "source": [
        "# 1.0 An end-to-end classification problem (Data Check)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh34gim6KPtT"
      },
      "source": [
        "## 1.1 Dataset description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE8OJoDZ5AFK"
      },
      "source": [
        "We'll be looking at individual income in the United States. The **data** is from the **1994 census**, and contains information on an individual's **marital status**, **age**, **type of work**, and more. The **target column**, or what we want to predict, is whether individuals make less than or equal to 50k a year, or more than **50k a year**.\n",
        "\n",
        "You can download the data from the [University of California, Irvine's website](http://archive.ics.uci.edu/ml/datasets/Adult).\n",
        "\n",
        "Let's take the following steps:\n",
        "\n",
        "1. ETL (done!!!)\n",
        "4. Data Checks\n",
        "\n",
        "<center><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1a-nyAPNPiVh-Xb2Pu2t2p-BhSvHJS0pO\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UpxKxU1Ej7f"
      },
      "source": [
        "## 1.2 Install, load libraries and setup wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t82KewAPWCYe"
      },
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytest pytest-sugar"
      ],
      "metadata": {
        "id": "IumW4s8Sh9i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LASaVZuhRJlL"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Login to Weights & Biases\n",
        "!wandb login c31b37325ded6fca6cc264d97e82531864b3d69a"
      ],
      "metadata": {
        "id": "QZXcN54GkP25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4286d078-0370-41aa-80ef-d9c79ed41f86"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Pytest\n"
      ],
      "metadata": {
        "id": "MPjpyeU7d37l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB1QY4sbPs4-"
      },
      "source": [
        "### 1.2.1 How pytest discovers tests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "pytests uses the following [conventions](https://docs.pytest.org/en/latest/goodpractices.html#conventions-for-python-test-discovery) to automatically discovering tests:\n",
        "  1. files with tests should be called `test_*.py` or `*_test.py `\n",
        "  2. test function name should start with `test_`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gXlqh21wiW6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Fixture"
      ],
      "metadata": {
        "id": "JtTD3oxoiYF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "An important aspect when using ``pytest`` is understanding the fixture's scope works.\n",
        "\n",
        "The scope of the fixture can have a few legal values, described [here](https://docs.pytest.org/en/6.2.x/fixture.html#fixture-scopes). We are going to consider only **session** and **function**: with the former, the fixture is executed only once in a pytest session and the value it returns is used for all the tests that need it; with the latter, every test function gets a fresh copy of the data. This is useful if the tests modify the input in a way that make the other tests fail, for example."
      ],
      "metadata": {
        "id": "mwNz2mgMevJJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJjWla1qxd3i"
      },
      "source": [
        "### 1.2.3 Create and run a test file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9acpZigRVANF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86db99fc-423a-423d-ccb5-61d331bc0f44"
      },
      "source": [
        "%%file test_data.py\n",
        "import pytest\n",
        "import wandb\n",
        "import pandas as pd\n",
        "\n",
        "# This is global so all tests are collected under the same run\n",
        "run = wandb.init(project=\"decision_tree\", job_type=\"data_checks\")\n",
        "\n",
        "@pytest.fixture(scope=\"session\")\n",
        "def data():\n",
        "\n",
        "    local_path = run.use_artifact(\"decision_tree/preprocessed_data.csv:latest\").file()\n",
        "    df = pd.read_csv(local_path)\n",
        "\n",
        "    return df\n",
        "\n",
        "def test_data_length(data):\n",
        "    \"\"\"\n",
        "    We test that we have enough data to continue\n",
        "    \"\"\"\n",
        "    assert len(data) > 1000\n",
        "\n",
        "\n",
        "def test_number_of_columns(data):\n",
        "    \"\"\"\n",
        "    We test that we have enough data to continue\n",
        "    \"\"\"\n",
        "    assert data.shape[1] == 15\n",
        "\n",
        "def test_column_presence_and_type(data):\n",
        "\n",
        "    required_columns = {\n",
        "        \"age\": pd.api.types.is_int64_dtype,\n",
        "        \"workclass\": pd.api.types.is_object_dtype,\n",
        "        \"fnlwgt\": pd.api.types.is_int64_dtype,\n",
        "        \"education\": pd.api.types.is_object_dtype,\n",
        "        \"education_num\": pd.api.types.is_int64_dtype,\n",
        "        \"marital_status\": pd.api.types.is_object_dtype,\n",
        "        \"occupation\": pd.api.types.is_object_dtype,\n",
        "        \"relationship\": pd.api.types.is_object_dtype,\n",
        "        \"race\": pd.api.types.is_object_dtype,\n",
        "        \"sex\": pd.api.types.is_object_dtype,\n",
        "        \"capital_gain\": pd.api.types.is_int64_dtype,\n",
        "        \"capital_loss\": pd.api.types.is_int64_dtype,\n",
        "        \"hours_per_week\": pd.api.types.is_int64_dtype,\n",
        "        \"native_country\": pd.api.types.is_object_dtype,\n",
        "        \"high_income\": pd.api.types.is_object_dtype\n",
        "    }\n",
        "\n",
        "    # Check column presence\n",
        "    assert set(data.columns.values).issuperset(set(required_columns.keys()))\n",
        "\n",
        "    for col_name, format_verification_funct in required_columns.items():\n",
        "\n",
        "        assert format_verification_funct(data[col_name]), f\"Column {col_name} failed test {format_verification_funct}\"\n",
        "\n",
        "\n",
        "def test_class_names(data):\n",
        "\n",
        "    # Check that only the known classes are present\n",
        "    known_classes = [\n",
        "        \" <=50K\",\n",
        "        \" >50K\"\n",
        "    ]\n",
        "\n",
        "    assert data[\"high_income\"].isin(known_classes).all()\n",
        "\n",
        "\n",
        "def test_column_ranges(data):\n",
        "\n",
        "    ranges = {\n",
        "        \"age\": (17, 90),\n",
        "        \"fnlwgt\": (1.228500e+04, 1.484705e+06),\n",
        "        \"education_num\": (1, 16),\n",
        "        \"capital_gain\": (0, 99999),\n",
        "        \"capital_loss\": (0, 4356),\n",
        "        \"hours_per_week\": (1, 99)\n",
        "    }\n",
        "\n",
        "    for col_name, (minimum, maximum) in ranges.items():\n",
        "\n",
        "        assert data[col_name].dropna().between(minimum, maximum).all(), (\n",
        "            f\"Column {col_name} failed the test. Should be between {minimum} and {maximum}, \"\n",
        "            f\"instead min={data[col_name].min()} and max={data[col_name].max()}\"\n",
        "        )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTBnZ3-vVe0p"
      },
      "source": [
        "Now lets run pytest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXBQkMc8VeD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e4afb4-ec6c-4d3f-b367-f4109ec81b45"
      },
      "source": [
        "!pytest . -vv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTest session starts (platform: linux, Python 3.10.12, pytest 7.4.4, pytest-sugar 1.0.0)\u001b[0m\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content\n",
            "plugins: sugar-1.0.0, anyio-3.7.1\n",
            "collected 5 items                                                                                  \u001b[0m\n",
            "\n",
            " \u001b[36mtest_data.py\u001b[0m::test_data_length\u001b[0m \u001b[32m✓\u001b[0m                                                     \u001b[32m20% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█        \u001b[0m\n",
            " \u001b[36mtest_data.py\u001b[0m::test_number_of_columns\u001b[0m \u001b[32m✓\u001b[0m                                               \u001b[32m40% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█      \u001b[0m\n",
            " \u001b[36mtest_data.py\u001b[0m::test_column_presence_and_type\u001b[0m \u001b[32m✓\u001b[0m                                        \u001b[32m60% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█    \u001b[0m\n",
            " \u001b[36mtest_data.py\u001b[0m::test_class_names\u001b[0m \u001b[32m✓\u001b[0m                                                     \u001b[32m80% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█  \u001b[0m\n",
            " \u001b[36mtest_data.py\u001b[0m::test_column_ranges\u001b[0m \u001b[32m✓\u001b[0m                                                  \u001b[32m100% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\n",
            "\n",
            "Results (4.55s):\n",
            "\u001b[32m       5 passed\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# close the run\n",
        "# waiting a while after run the previous cell before execute this\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "5284u1A7euMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FpvJLXccv8Kz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}